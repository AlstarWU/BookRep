{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第6章·实验4：面向时序分析的 CNN",
        "",
        "本 Notebook 以一维卷积网络完成合成时序数据的分类任务，覆盖数据准备、模型搭建、训练评估和实验思考环节，便于直接运行或在课件要求基础上改动参数重现实验。主要步骤：",
        "",
        "1. 构造带噪声的双类别时序数据（正弦波 vs. 方波）。",
        "2. 使用 `DataLoader` 划分训练/验证/测试集并可视化样本。",
        "3. 搭建一维卷积网络（Conv1d + BatchNorm + Dropout）。",
        "4. 训练与验证，记录损失与精度曲线，评估测试集并展示混淆矩阵。",
        "5. 预留思考与扩展小节，按照课件的“实验要求”整理观察与结论。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境与依赖",
        "- 依赖：`torch`, `numpy`, `matplotlib`, `scikit-learn`（如缺失可 `pip install`）。",
        "- 建议 GPU 可用时自动切换到 CUDA。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 保持可重复性\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 生成与准备时序数据",
        "- 类别 0：含噪声的正弦波；类别 1：含噪声的方波。",
        "- 每个样本长度固定（默认为 200），可根据实验要求修改。",
        "- 划分训练/验证/测试集，并归一化到 [-1, 1] 范围。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def generate_wave(sample_len: int, kind: str, noise_scale: float = 0.1) -> np.ndarray:\n",
        "    x = np.linspace(0, 2 * math.pi, sample_len)\n",
        "    if kind == \"sine\":\n",
        "        base = np.sin(x)\n",
        "    elif kind == \"square\":\n",
        "        base = np.sign(np.sin(x))\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported kind\")\n",
        "    noise = np.random.normal(scale=noise_scale, size=sample_len)\n",
        "    return base + noise\n",
        "\n",
        "def build_dataset(n_samples: int = 1200, sample_len: int = 200) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    signals = []\n",
        "    labels = []\n",
        "    for _ in range(n_samples // 2):\n",
        "        signals.append(generate_wave(sample_len, \"sine\"))\n",
        "        labels.append(0)\n",
        "        signals.append(generate_wave(sample_len, \"square\"))\n",
        "        labels.append(1)\n",
        "    signals = np.stack(signals).astype(np.float32)\n",
        "    labels = np.array(labels, dtype=np.int64)\n",
        "    # 归一化到 [-1, 1]\n",
        "    max_val = np.abs(signals).max()\n",
        "    signals = signals / max_val\n",
        "    return signals, labels\n",
        "\n",
        "class WaveformDataset(Dataset):\n",
        "    def __init__(self, signals: np.ndarray, labels: np.ndarray):\n",
        "        self.signals = torch.tensor(signals)\n",
        "        self.labels = torch.tensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Conv1d 期望形状: (C, L)，这里 C=1\n",
        "        return self.signals[idx].unsqueeze(0), self.labels[idx]\n",
        "\n",
        "signals, labels = build_dataset(n_samples=1200, sample_len=200)\n",
        "\n",
        "# 划分数据集\n",
        "total = len(labels)\n",
        "indices = np.random.permutation(total)\n",
        "train_end = int(total * 0.7)\n",
        "val_end = int(total * 0.85)\n",
        "train_idx, val_idx, test_idx = indices[:train_end], indices[train_end:val_end], indices[val_end:]\n",
        "\n",
        "train_data = WaveformDataset(signals[train_idx], labels[train_idx])\n",
        "val_data = WaveformDataset(signals[val_idx], labels[val_idx])\n",
        "test_data = WaveformDataset(signals[test_idx], labels[test_idx])\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "len(train_data), len(val_data), len(test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 样本可视化",
        "从训练集抽取若干条曲线，确认类别差异与噪声分布是否符合预期。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "samples_to_plot = 3\n",
        "fig, axes = plt.subplots(samples_to_plot, 2, figsize=(10, 6), sharex=True, sharey=True)\n",
        "for row in range(samples_to_plot):\n",
        "    for col, label in enumerate([0, 1]):\n",
        "        idx = (labels == label).nonzero()[0][row]\n",
        "        axes[row, col].plot(signals[idx])\n",
        "        axes[row, col].set_title(f\"label={label}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 构建一维卷积网络",
        "网络结构示例：Conv1d → BatchNorm → ReLU → Dropout → 池化，多层堆叠后接全连接分类器。可以根据课件实验要求自由调整通道数、卷积核大小或加入残差块。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TimeSeriesCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int = 2):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv1d(1, 16, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.MaxPool1d(kernel_size=2),\n",
        "\n",
        "            nn.Conv1d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(32, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "model = TimeSeriesCNN().to(device)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 训练、验证与评估",
        "- 使用交叉熵损失与 Adam 优化器。",
        "- 记录训练/验证损失与准确率，便于绘制学习曲线。",
        "- 可根据课件要求增加早停、学习率调度、更多指标等。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def train_one_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * y.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "def run_training(model, train_loader, val_loader, epochs=20, lr=1e-3):\n",
        "    history = defaultdict(list)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        print(f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f} \"\n",
        "              f\"train_acc={train_acc:.3f} val_acc={val_acc:.3f}\")\n",
        "    return history\n",
        "\n",
        "history = run_training(model, train_loader, val_loader, epochs=20, lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 学习曲线",
        "观察损失与准确率随 epoch 的变化趋势，检查是否过拟合或欠拟合。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "axes[0].plot(history[\"train_loss\"], label=\"train\")\n",
        "axes[0].plot(history[\"val_loss\"], label=\"val\")\n",
        "axes[0].set_title(\"Loss\")\n",
        "axes[0].legend()\n",
        "axes[1].plot(history[\"train_acc\"], label=\"train\")\n",
        "axes[1].plot(history[\"val_acc\"], label=\"val\")\n",
        "axes[1].set_title(\"Accuracy\")\n",
        "axes[1].legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 测试集评估与混淆矩阵",
        "输出分类报告和混淆矩阵，结合实验要求撰写分析（如优势、可能的改进方向）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
        "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.3f}\")\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.to(device)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(dim=1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(y.numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"sine\", \"square\"]))\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "im = ax.imshow(cm, cmap=\"Blues\")\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_yticks([0, 1])\n",
        "ax.set_xticklabels([\"sine\", \"square\"])\n",
        "ax.set_yticklabels([\"sine\", \"square\"])\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel(\"True\")\n",
        "for (i, j), val in np.ndenumerate(cm):\n",
        "    ax.text(j, i, int(val), ha=\"center\", va=\"center\", color=\"black\")\n",
        "fig.colorbar(im)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 思考与拓展（与课件实验要求对应）",
        "- **网络结构对比**：尝试不同卷积核大小/层数，记录验证集表现。",
        "- **正则化与泛化**：对比 Dropout/BatchNorm 关闭或调整后的变化。",
        "- **数据与窗口**：修改序列长度或增加噪声，观察鲁棒性。",
        "- **实验结论**：总结 CNN 在时序分类中的优势、存在问题及改进思路。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}